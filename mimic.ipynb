{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32650386-bcb8-4c05-a70a-229a67bc8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two options - randomly pair (brain, face, spine) reports or if there are an equal number, you can deterministically pair\n",
    "# we provide both options in the next two cells\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "BRAIN_DIR = \"MIMIC/partitioned_by_report\"\n",
    "FACE_DIR = \"MIMIC/partitioned_by_report_face\"\n",
    "SPINE_DIR = \"MIMIC/partitioned_by_report_spine\"\n",
    "OUTPUT_DIR = \"MIMIC/synthetic_concat_reports\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "brain_files = [f for f in os.listdir(BRAIN_DIR) if f.endswith('.csv')]\n",
    "face_files = [f for f in os.listdir(FACE_DIR) if f.endswith('.csv')]\n",
    "spine_files = [f for f in os.listdir(SPINE_DIR) if f.endswith('.csv')]\n",
    "\n",
    "for i, brain_file in enumerate(brain_files):\n",
    "    brain_path = os.path.join(BRAIN_DIR, brain_file)\n",
    "    face_file = random.choice(face_files)\n",
    "    face_path = os.path.join(FACE_DIR, face_file)\n",
    "    spine_file = random.choice(spine_files)\n",
    "    spine_path = os.path.join(SPINE_DIR, spine_file)\n",
    "    \n",
    "    df_brain = pd.read_csv(brain_path)\n",
    "    df_face = pd.read_csv(face_path)\n",
    "    df_spine = pd.read_csv(spine_path)\n",
    "\n",
    "    for df in [df_brain, df_face, df_spine]:\n",
    "        if \"sentence\" in df.columns:\n",
    "            df.rename(columns={\"sentence\": \"Sentence\"}, inplace=True)\n",
    "        if \"sentence_num\" in df.columns:\n",
    "            df.rename(columns={\"sentence_num\": \"Sentence Num\"}, inplace=True)\n",
    "        if \"report_index\" in df.columns:\n",
    "            df.drop(columns=[\"report_index\"], inplace=True)\n",
    "        if \"Brain Related\" not in df:\n",
    "            df[\"Brain Related\"] = -1\n",
    "        df[\"Brain Related\"] = df[\"Brain Related\"].fillna(-1).astype(int)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    # reset sentence numbers sequentially\n",
    "    def reset_sentence_num(dfs):\n",
    "        all_dfs = []\n",
    "        current_num = 1\n",
    "        for df in dfs:\n",
    "            df = df.copy()\n",
    "            n = len(df)\n",
    "            df[\"Sentence Num\"] = np.arange(current_num, current_num + n)\n",
    "            current_num += n\n",
    "            all_dfs.append(df)\n",
    "        return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    brain_only = reset_sentence_num([df_brain])\n",
    "    brain_only.to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_{i:03d}.csv\"), index=False)\n",
    "\n",
    "    brain_face = reset_sentence_num([df_brain, df_face])\n",
    "    brain_face.to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_face_{i:03d}.csv\"), index=False)\n",
    "\n",
    "    brain_spine = reset_sentence_num([df_brain, df_spine])\n",
    "    brain_spine.to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_spine_{i:03d}.csv\"), index=False)\n",
    "\n",
    "    trio_order = [df_brain, df_face, df_spine]\n",
    "    if random.choice([True, False]):\n",
    "        # brain + face + spine\n",
    "        ordered_trio = trio_order\n",
    "        filename = f\"synthetic_brain_face_spine_{i:03d}.csv\"\n",
    "    else:\n",
    "        # brain + spine + face\n",
    "        ordered_trio = [df_brain, df_spine, df_face]\n",
    "        filename = f\"synthetic_brain_spine_face_{i:03d}.csv\"\n",
    "    trio_df = reset_sentence_num(ordered_trio)\n",
    "    trio_df.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\n",
    "\n",
    "    print(f\"Saved synthetic reports for brain report {i+1}/{len(brain_files)}\")\n",
    "\n",
    "print(\"All synthetic reports generated in\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1588d-8086-4a4f-bf9d-d606b608e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BRAIN_DIR = \"MIMIC/partitioned_by_report\"\n",
    "FACE_DIR  = \"MIMIC/partitioned_by_report_face\"\n",
    "SPINE_DIR = \"MIMIC/partitioned_by_report_spine\"\n",
    "OUTPUT_DIR = \"MIMIC/synthetic_concat_reports\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "brain_files = sorted([f for f in os.listdir(BRAIN_DIR) if f.endswith('.csv')])\n",
    "face_files  = sorted([f for f in os.listdir(FACE_DIR)  if f.endswith('.csv')])\n",
    "spine_files = sorted([f for f in os.listdir(SPINE_DIR) if f.endswith('.csv')])\n",
    "\n",
    "assert len(brain_files) == len(face_files) == len(spine_files), \"Counts must match\"\n",
    "\n",
    "def reset_sentence_num(dfs):\n",
    "    all_dfs = []\n",
    "    current = 1\n",
    "    for df in dfs:\n",
    "        df = df.copy()\n",
    "        n = len(df)\n",
    "        df[\"Sentence Num\"] = np.arange(current, current + n)\n",
    "        current += n\n",
    "        all_dfs.append(df)\n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "for i, (brain_file, face_file, spine_file) in enumerate(zip(brain_files, face_files, spine_files)):\n",
    "    brain_path = os.path.join(BRAIN_DIR, brain_file)\n",
    "    face_path  = os.path.join(FACE_DIR,  face_file)\n",
    "    spine_path = os.path.join(SPINE_DIR, spine_file)\n",
    "\n",
    "    df_brain = pd.read_csv(brain_path)\n",
    "    df_face  = pd.read_csv(face_path)\n",
    "    df_spine = pd.read_csv(spine_path)\n",
    "\n",
    "    for df in (df_brain, df_face, df_spine):\n",
    "        if \"sentence\" in df.columns: df.rename(columns={\"sentence\": \"Sentence\"}, inplace=True)\n",
    "        if \"sentence_num\" in df.columns: df.rename(columns={\"sentence_num\": \"Sentence Num\"}, inplace=True)\n",
    "        if \"report_index\" in df.columns: df.drop(columns=[\"report_index\"], inplace=True)\n",
    "        if \"Unnamed: 0\" in df.columns: df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "        if \"Brain Related\" not in df: df[\"Brain Related\"] = -1\n",
    "        df[\"Brain Related\"] = df[\"Brain Related\"].fillna(-1).astype(int)\n",
    "\n",
    "    reset_sentence_num([df_brain]).to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_{i:03d}.csv\"), index=False)\n",
    "\n",
    "    reset_sentence_num([df_brain, df_face]).to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_face_{i:03d}.csv\"), index=False)\n",
    "\n",
    "    reset_sentence_num([df_brain, df_spine]).to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_spine_{i:03d}.csv\"), index=False)\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        ordered = [df_brain, df_face, df_spine]\n",
    "        fname = f\"synthetic_brain_face_spine_{i:03d}.csv\"\n",
    "    else:\n",
    "        ordered = [df_brain, df_spine, df_face]\n",
    "        fname = f\"synthetic_brain_spine_face_{i:03d}.csv\"\n",
    "\n",
    "    reset_sentence_num(ordered).to_csv(os.path.join(OUTPUT_DIR, fname), index=False)\n",
    "\n",
    "    print(f\"Saved synthetic reports for brain report {i+1}/{len(brain_files)}\")\n",
    "\n",
    "print(\"All synthetic reports generated in\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd50277-196a-4980-a920-3876b6aef204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual reports\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BRAIN_DIR = \"MIMIC/partitioned_by_report\"\n",
    "FACE_DIR  = \"MIMIC/partitioned_by_report_face\"\n",
    "SPINE_DIR = \"MIMIC/partitioned_by_report_spine\"\n",
    "OUTPUT_DIR = \"MIMIC/real_individual_reports\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def list_csvs(d):\n",
    "    return sorted([f for f in os.listdir(d) if f.endswith(\".csv\")])\n",
    "\n",
    "brain_files = list_csvs(BRAIN_DIR)\n",
    "face_files  = list_csvs(FACE_DIR)\n",
    "spine_files = list_csvs(SPINE_DIR)\n",
    "\n",
    "def load_and_standardize(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"sentence\": \"Sentence\",\n",
    "        \"sentence_num\": \"Sentence Num\",\n",
    "        \"report_index\": \"Report Index\"\n",
    "    })\n",
    "\n",
    "    if \"Brain Related\" not in df.columns:\n",
    "        df[\"Brain Related\"] = -1\n",
    "\n",
    "    return df\n",
    "\n",
    "def copy_reports(files, source_dir, prefix):\n",
    "    for fname in files:\n",
    "        src_path = os.path.join(source_dir, fname)\n",
    "        df = load_and_standardize(src_path)\n",
    "\n",
    "        out_path = os.path.join(OUTPUT_DIR, f\"{prefix}_{fname}\")\n",
    "        if os.path.exists(out_path):\n",
    "            print(f\"Skipping (already exists): {out_path}\")\n",
    "            continue\n",
    "\n",
    "        df.to_csv(out_path, index=False)\n",
    "        print(f\"Saved {len(df)} rows â†’ {out_path}\")\n",
    "\n",
    "copy_reports(brain_files, BRAIN_DIR, \"brain\")\n",
    "copy_reports(face_files,  FACE_DIR,  \"face\")\n",
    "copy_reports(spine_files, SPINE_DIR, \"spine\")\n",
    "\n",
    "print(\"All individual reports copied to\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118e055-b8d0-4978-b238-e51a992ec796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrambling reports together\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "BRAIN_DIR = \"MIMIC/partitioned_by_report\"\n",
    "FACE_DIR  = \"MIMIC/partitioned_by_report_face\"\n",
    "SPINE_DIR = \"MIMIC/partitioned_by_report_spine\"\n",
    "OUTPUT_DIR = \"MIMIC/synthetic_scrambled_reports\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def list_csvs(d):\n",
    "    return sorted([f for f in os.listdir(d) if f.endswith(\".csv\")])\n",
    "\n",
    "def load_and_standardize(path):\n",
    "    \"\"\"Load a per-report CSV and standardize columns.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"sentence\": \"Sentence\",\n",
    "        \"sentence_num\": \"Sentence Num\",\n",
    "        \"report_index\": \"Report Index\",\n",
    "    })\n",
    "\n",
    "    if \"Brain Related\" not in df.columns:\n",
    "        df[\"Brain Related\"] = -1\n",
    "\n",
    "    # we will reassign sentence num after scrambling anyway\n",
    "    return df\n",
    "\n",
    "def scramble_and_renumber(df, rng):\n",
    "    if len(df) == 0:\n",
    "        out = df.copy()\n",
    "        out[\"Sentence Num\"] = []\n",
    "        return out\n",
    "    rs = int(rng.integers(0, 2**32 - 1))\n",
    "    out = df.sample(frac=1.0, random_state=rs).reset_index(drop=True).copy()\n",
    "    out[\"Sentence Num\"] = np.arange(1, len(out) + 1)\n",
    "    return out\n",
    "\n",
    "def concat_scramble_renumber(dfs, rng):\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    return scramble_and_renumber(combined, rng)\n",
    "\n",
    "brain_files = list_csvs(BRAIN_DIR)\n",
    "face_files  = list_csvs(FACE_DIR)\n",
    "spine_files = list_csvs(SPINE_DIR)\n",
    "\n",
    "for i, brain_fname in enumerate(brain_files):\n",
    "    brain_path = os.path.join(BRAIN_DIR, brain_fname)\n",
    "    face_path  = os.path.join(FACE_DIR,  random.choice(face_files))\n",
    "    spine_path = os.path.join(SPINE_DIR, random.choice(spine_files))\n",
    "\n",
    "    df_brain = load_and_standardize(brain_path)\n",
    "    df_face  = load_and_standardize(face_path)\n",
    "    df_spine = load_and_standardize(spine_path)\n",
    "\n",
    "    brain_only_scr = scramble_and_renumber(df_brain, rng)\n",
    "    brain_only_path = os.path.join(OUTPUT_DIR, f\"scrambled_brain_{i:03d}.csv\")\n",
    "    brain_only_scr.to_csv(brain_only_path, index=False)\n",
    "\n",
    "    brain_face_scr = concat_scramble_renumber([df_brain, df_face], rng)\n",
    "    brain_face_path = os.path.join(OUTPUT_DIR, f\"scrambled_brain_face_{i:03d}.csv\")\n",
    "    brain_face_scr.to_csv(brain_face_path, index=False)\n",
    "\n",
    "    brain_spine_scr = concat_scramble_renumber([df_brain, df_spine], rng)\n",
    "    brain_spine_path = os.path.join(OUTPUT_DIR, f\"scrambled_brain_spine_{i:03d}.csv\")\n",
    "    brain_spine_scr.to_csv(brain_spine_path, index=False)\n",
    "\n",
    "    if random.choice([True, False]):\n",
    "        trio_dfs = [df_brain, df_face, df_spine]\n",
    "        trio_name = f\"scrambled_brain_face_spine_{i:03d}.csv\"\n",
    "    else:\n",
    "        trio_dfs = [df_brain, df_spine, df_face]\n",
    "        trio_name = f\"scrambled_brain_spine_face_{i:03d}.csv\"\n",
    "    trio_scr = concat_scramble_renumber(trio_dfs, rng)\n",
    "    trio_path = os.path.join(OUTPUT_DIR, trio_name)\n",
    "    trio_scr.to_csv(trio_path, index=False)\n",
    "\n",
    "    print(f\"Saved scrambled variants for brain report {i+1}/{len(brain_files)}\")\n",
    "\n",
    "print(\"All scrambled reports written to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06073fd4-f58b-40a7-9cd5-88e64a8ec6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "BRAIN_DIR = \"MIMIC/partitioned_by_report\"\n",
    "FACE_DIR = \"MIMIC/partitioned_by_report_face\"\n",
    "SPINE_DIR = \"MIMIC/partitioned_by_report_spine\"\n",
    "OUTPUT_DIR = \"MIMIC/synthetic_bundled_reports\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SECTION_HEADERS = [\n",
    "    \"EXAMINATION\", \"EXAM\",\n",
    "    \"HISTORY\", \"HIST\",\n",
    "    \"INDICATION\", \"IND\",\n",
    "    \"TECHNIQUE\", \"TECH\",\n",
    "    \"DOSE\",\n",
    "    \"COMPARISON\", \"COMP\",\n",
    "    \"FINDINGS\", \"FIND\",\n",
    "    \"IMPRESSIONS\", \"IMPRESSION\", \"IMP\",\n",
    "    \"NOTIFICATION\", \"NOTIFY\",\n",
    "    \"RECOMMENDATIONS\", \"RECOMMENDATION\", \"REC\"\n",
    "]\n",
    "\n",
    "# only write these three sections to csv (in this order) - these are the most important sections for filtering information and the history sections, etc may have conflicting information that wouldn't make sense to merge\n",
    "ALLOWED_SECTIONS = [\"EXAMINATION\", \"FINDINGS\", \"IMPRESSIONS\"]\n",
    "\n",
    "def extract_sections(text: str) -> Dict[str, str]:\n",
    "    if not text or pd.isna(text):\n",
    "        return {}\n",
    "    text = str(text).strip()\n",
    "    sections = {}\n",
    "\n",
    "    header_pattern = r'\\b(' + '|'.join(SECTION_HEADERS) + r')(?:\\s*:|\\s*\\n|\\s+)'\n",
    "    matches = list(re.finditer(header_pattern, text, re.IGNORECASE))\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        header = match.group(1).upper()\n",
    "        start_pos = match.end()\n",
    "        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        content = text[start_pos:end_pos].strip()\n",
    "\n",
    "        if header in [\"EXAM\"]:\n",
    "            header = \"EXAMINATION\"\n",
    "        elif header in [\"HIST\"]:\n",
    "            header = \"HISTORY\"\n",
    "        elif header in [\"IND\"]:\n",
    "            header = \"INDICATION\"\n",
    "        elif header in [\"TECH\"]:\n",
    "            header = \"TECHNIQUE\"\n",
    "        elif header in [\"COMP\"]:\n",
    "            header = \"COMPARISON\"\n",
    "        elif header in [\"FIND\"]:\n",
    "            header = \"FINDINGS\"\n",
    "        elif header in [\"IMPRESSION\", \"IMP\"]:\n",
    "            header = \"IMPRESSIONS\"\n",
    "        elif header in [\"NOTIFY\"]:\n",
    "            header = \"NOTIFICATION\"\n",
    "        elif header in [\"RECOMMENDATIONS\", \"REC\"]:\n",
    "            header = \"RECOMMENDATION\"\n",
    "\n",
    "        if content:\n",
    "            sections[header] = content\n",
    "    return sections\n",
    "\n",
    "def get_report_text(df: pd.DataFrame) -> str:\n",
    "    if 'Sentence' not in df.columns:\n",
    "        return \"\"\n",
    "    sentences = df['Sentence'].dropna().tolist()\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "def text_to_sentences(text: str) -> List[str]: # this suffices for the reports we labeled but more complex handling may be needed for larger scale experiments\n",
    "    if not text:\n",
    "        return []\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def merge_sections_labeled(sections_list: List[Dict[str, str]], labels: List[int]) -> Dict[str, List[Tuple[str, int]]]:\n",
    "    full_order = [\n",
    "        \"EXAMINATION\", \"HISTORY\", \"INDICATION\", \"TECHNIQUE\",\n",
    "        \"DOSE\", \"COMPARISON\", \"FINDINGS\", \"IMPRESSIONS\",\n",
    "        \"NOTIFICATION\", \"RECOMMENDATION\"\n",
    "    ]\n",
    "    merged: Dict[str, List[Tuple[str, int]]] = {}\n",
    "    for section in full_order:\n",
    "        parts = []\n",
    "        for sec_dict, lab in zip(sections_list, labels):\n",
    "            if section in sec_dict and sec_dict[section].strip():\n",
    "                parts.append((sec_dict[section], lab))\n",
    "        if parts:\n",
    "            merged[section] = parts\n",
    "    return merged\n",
    "\n",
    "def flatten_exam_to_single_sentence(exam_parts: List[Tuple[str, int]]) -> Tuple[str, int]:\n",
    "    contents = [c for c, _ in exam_parts if c and c.strip()]\n",
    "    if not contents:\n",
    "        return (\"\", 1)\n",
    "    combined = ' '.join(contents).replace('\\n', ' ')\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    combined = re.sub(r'[.!?;:]+', '', combined).strip()\n",
    "    return (combined, 1)\n",
    "\n",
    "def create_dataframe_from_merged(merged_labeled: Dict[str, List[Tuple[str, int]]]) -> pd.DataFrame:\n",
    "    # forcing the examination section to be labeled all 1 for inclusion information because we opt to want the header included\n",
    "    sentences: List[str] = []\n",
    "    labels: List[int] = []\n",
    "\n",
    "    if \"EXAMINATION\" in merged_labeled:\n",
    "        exam_sentence, exam_label = flatten_exam_to_single_sentence(merged_labeled[\"EXAMINATION\"])\n",
    "        if exam_sentence:\n",
    "            sentences.append(exam_sentence)\n",
    "            labels.append(1)  # force label\n",
    "\n",
    "    for section in [\"FINDINGS\", \"IMPRESSIONS\"]:\n",
    "        if section in merged_labeled:\n",
    "            for content, lab in merged_labeled[section]:\n",
    "                for s in text_to_sentences(content):\n",
    "                    sentences.append(s)\n",
    "                    labels.append(lab)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Sentence\": sentences,\n",
    "        \"Sentence Num\": range(1, len(sentences) + 1),\n",
    "        \"Brain Related\": labels\n",
    "    })\n",
    "    return df\n",
    "\n",
    "brain_files = [f for f in os.listdir(BRAIN_DIR) if f.endswith('.csv')]\n",
    "face_files = [f for f in os.listdir(FACE_DIR) if f.endswith('.csv')]\n",
    "spine_files = [f for f in os.listdir(SPINE_DIR) if f.endswith('.csv')]\n",
    "\n",
    "for i, brain_file in enumerate(brain_files):\n",
    "    brain_path = os.path.join(BRAIN_DIR, brain_file)\n",
    "    # can also remove randomness in the same way - for lack of redundancy and generality, we just provide this script\n",
    "    face_file = random.choice(face_files)\n",
    "    face_path = os.path.join(FACE_DIR, face_file)\n",
    "    spine_file = random.choice(spine_files)\n",
    "    spine_path = os.path.join(SPINE_DIR, spine_file)\n",
    "    \n",
    "    df_brain = pd.read_csv(brain_path)\n",
    "    df_face = pd.read_csv(face_path)\n",
    "    df_spine = pd.read_csv(spine_path)\n",
    "    \n",
    "    for df in [df_brain, df_face, df_spine]:\n",
    "        if \"sentence\" in df.columns:\n",
    "            df.rename(columns={\"sentence\": \"Sentence\"}, inplace=True)\n",
    "        if \"sentence_num\" in df.columns:\n",
    "            df.rename(columns={\"sentence_num\": \"Sentence Num\"}, inplace=True)\n",
    "        if \"report_index\" in df.columns:\n",
    "            df.drop(columns=[\"report_index\"], inplace=True)\n",
    "        if \"Brain Related\" not in df.columns:\n",
    "            df[\"Brain Related\"] = -1\n",
    "        df[\"Brain Related\"] = df[\"Brain Related\"].fillna(-1).astype(int)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    \n",
    "    brain_text = get_report_text(df_brain)\n",
    "    face_text = get_report_text(df_face)\n",
    "    spine_text = get_report_text(df_spine)\n",
    "    \n",
    "    brain_sections = extract_sections(brain_text)\n",
    "    face_sections = extract_sections(face_text)\n",
    "    spine_sections = extract_sections(spine_text)\n",
    "\n",
    "    merged_b_only = merge_sections_labeled([brain_sections], [1])\n",
    "    df_brain_only = create_dataframe_from_merged(merged_b_only)\n",
    "    df_brain_only.to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_{i:03d}.csv\"), index=False)\n",
    "    \n",
    "    merged_bf_labeled = merge_sections_labeled([brain_sections, face_sections], [1, 0])\n",
    "    df_brain_face = create_dataframe_from_merged(merged_bf_labeled)\n",
    "    df_brain_face.to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_face_{i:03d}.csv\"), index=False)\n",
    "    \n",
    "    merged_bs_labeled = merge_sections_labeled([brain_sections, spine_sections], [1, 0])\n",
    "    df_brain_spine = create_dataframe_from_merged(merged_bs_labeled)\n",
    "    df_brain_spine.to_csv(os.path.join(OUTPUT_DIR, f\"synthetic_brain_spine_{i:03d}.csv\"), index=False)\n",
    "    \n",
    "    if random.choice([True, False]):\n",
    "        merged_trio_labeled = merge_sections_labeled([brain_sections, face_sections, spine_sections], [1, 0, 0])\n",
    "        filename = f\"synthetic_brain_face_spine_{i:03d}.csv\"\n",
    "    else:\n",
    "        merged_trio_labeled = merge_sections_labeled([brain_sections, spine_sections, face_sections], [1, 0, 0])\n",
    "        filename = f\"synthetic_brain_spine_face_{i:03d}.csv\"\n",
    "    df_trio = create_dataframe_from_merged(merged_trio_labeled)\n",
    "    df_trio.to_csv(os.path.join(OUTPUT_DIR, filename), index=False)\n",
    "    \n",
    "    print(f\"Processed bundled reports\")\n",
    "\n",
    "print(\"All bundled reports generated in\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fe153-56c2-433d-8b44-b0e0436485df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation script that makes the reports fully independent \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "BRAIN_DIR = \"MIMIC/partitioned_by_report\"\n",
    "FACE_DIR = \"MIMIC/partitioned_by_report_face\"\n",
    "SPINE_DIR = \"MIMIC/partitioned_by_report_spine\"\n",
    "OUTPUT_DIR = \"MIMIC/synthetic_bundled_reports_deterministic\"\n",
    "SUFFIX = \"_deterministic\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SECTION_HEADERS = [\n",
    "    \"EXAMINATION\", \"EXAM\",\n",
    "    \"HISTORY\", \"HIST\",\n",
    "    \"INDICATION\", \"IND\",\n",
    "    \"TECHNIQUE\", \"TECH\",\n",
    "    \"DOSE\",\n",
    "    \"COMPARISON\", \"COMP\",\n",
    "    \"FINDINGS\", \"FIND\",\n",
    "    \"IMPRESSIONS\", \"IMPRESSION\", \"IMP\",\n",
    "    \"NOTIFICATION\", \"NOTIFY\",\n",
    "    \"RECOMMENDATIONS\", \"RECOMMENDATION\", \"REC\"\n",
    "]\n",
    "\n",
    "ALLOWED_SECTIONS = [\"EXAMINATION\", \"FINDINGS\", \"IMPRESSIONS\"]\n",
    "\n",
    "def extract_sections(text: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract sections from a medical report text.\"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return {}\n",
    "    text = str(text).strip()\n",
    "    sections = {}\n",
    "\n",
    "    header_pattern = r'\\b(' + '|'.join(SECTION_HEADERS) + r')(?:\\s*:|\\s*\\n|\\s+)'\n",
    "    matches = list(re.finditer(header_pattern, text, re.IGNORECASE))\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        header = match.group(1).upper()\n",
    "        start_pos = match.end()\n",
    "        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        content = text[start_pos:end_pos].strip()\n",
    "\n",
    "        if header in [\"EXAM\"]:\n",
    "            header = \"EXAMINATION\"\n",
    "        elif header in [\"HIST\"]:\n",
    "            header = \"HISTORY\"\n",
    "        elif header in [\"IND\"]:\n",
    "            header = \"INDICATION\"\n",
    "        elif header in [\"TECH\"]:\n",
    "            header = \"TECHNIQUE\"\n",
    "        elif header in [\"COMP\"]:\n",
    "            header = \"COMPARISON\"\n",
    "        elif header in [\"FIND\"]:\n",
    "            header = \"FINDINGS\"\n",
    "        elif header in [\"IMPRESSION\", \"IMP\"]:\n",
    "            header = \"IMPRESSIONS\"\n",
    "        elif header in [\"NOTIFY\"]:\n",
    "            header = \"NOTIFICATION\"\n",
    "        elif header in [\"RECOMMENDATIONS\", \"REC\"]:\n",
    "            header = \"RECOMMENDATION\"\n",
    "\n",
    "        if content:\n",
    "            sections[header] = content\n",
    "    return sections\n",
    "\n",
    "def get_report_text(df: pd.DataFrame) -> str:\n",
    "    if 'Sentence' not in df.columns:\n",
    "        return \"\"\n",
    "    sentences = df['Sentence'].dropna().tolist()\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "def text_to_sentences(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def merge_sections_labeled(sections_list: List[Dict[str, str]], labels: List[int]) -> Dict[str, List[Tuple[str, int]]]:\n",
    "    full_order = [\n",
    "        \"EXAMINATION\", \"HISTORY\", \"INDICATION\", \"TECHNIQUE\",\n",
    "        \"DOSE\", \"COMPARISON\", \"FINDINGS\", \"IMPRESSIONS\",\n",
    "        \"NOTIFICATION\", \"RECOMMENDATION\"\n",
    "    ]\n",
    "    merged: Dict[str, List[Tuple[str, int]]] = {}\n",
    "    for section in full_order:\n",
    "        parts = []\n",
    "        for sec_dict, lab in zip(sections_list, labels):\n",
    "            if section in sec_dict and sec_dict[section].strip():\n",
    "                parts.append((sec_dict[section], lab))\n",
    "        if parts:\n",
    "            merged[section] = parts\n",
    "    return merged\n",
    "\n",
    "def flatten_exam_to_single_sentence(exam_parts: List[Tuple[str, int]]) -> Tuple[str, int]:\n",
    "    contents = [c for c, _ in exam_parts if c and c.strip()]\n",
    "    if not contents:\n",
    "        return (\"\", 1)\n",
    "    combined = ' '.join(contents).replace('\\n', ' ')\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    combined = re.sub(r'[.!?;:]+', '', combined).strip()\n",
    "    return (combined, 1)\n",
    "\n",
    "def create_dataframe_from_merged(merged_labeled: Dict[str, List[Tuple[str, int]]]) -> pd.DataFrame:\n",
    "    sentences: List[str] = []\n",
    "    labels: List[int] = []\n",
    "\n",
    "    if \"EXAMINATION\" in merged_labeled:\n",
    "        exam_sentence, exam_label = flatten_exam_to_single_sentence(merged_labeled[\"EXAMINATION\"])\n",
    "        if exam_sentence:\n",
    "            sentences.append(exam_sentence)\n",
    "            labels.append(1)\n",
    "\n",
    "    for section in [\"FINDINGS\", \"IMPRESSIONS\"]:\n",
    "        if section in merged_labeled:\n",
    "            for content, lab in merged_labeled[section]:\n",
    "                for s in text_to_sentences(content):\n",
    "                    sentences.append(s)\n",
    "                    labels.append(lab)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Sentence\": sentences,\n",
    "        \"Sentence Num\": range(1, len(sentences) + 1),\n",
    "        \"Brain Related\": labels\n",
    "    })\n",
    "    return df\n",
    "\n",
    "brain_files = [f for f in os.listdir(BRAIN_DIR) if f.endswith('.csv')]\n",
    "face_files  = [f for f in os.listdir(FACE_DIR)  if f.endswith('.csv')]\n",
    "spine_files = [f for f in os.listdir(SPINE_DIR) if f.endswith('.csv')]\n",
    "\n",
    "print(len(brain_files))\n",
    "print(len(face_files))\n",
    "print(len(spine_files))\n",
    "limit = 100\n",
    "brain_files = brain_files[:limit]\n",
    "face_files  = face_files[:limit]\n",
    "spine_files = spine_files[:limit]\n",
    "assert len(brain_files) == len(face_files) == len(spine_files), \"Brain/Face/Spine counts must match\"\n",
    "\n",
    "# one time shuffles\n",
    "rng_b, rng_f, rng_s = random.Random(1), random.Random(2), random.Random(3)\n",
    "rng_b.shuffle(brain_files)\n",
    "rng_f.shuffle(face_files)\n",
    "rng_s.shuffle(spine_files)\n",
    "\n",
    "for i, (brain_file, face_file, spine_file) in enumerate(zip(brain_files, face_files, spine_files)):\n",
    "    brain_path = os.path.join(BRAIN_DIR, brain_file)\n",
    "    face_path  = os.path.join(FACE_DIR,  face_file)\n",
    "    spine_path = os.path.join(SPINE_DIR, spine_file)\n",
    "    \n",
    "    df_brain = pd.read_csv(brain_path)\n",
    "    df_face = pd.read_csv(face_path)\n",
    "    df_spine = pd.read_csv(spine_path)\n",
    "    \n",
    "    for df in [df_brain, df_face, df_spine]:\n",
    "        if \"sentence\" in df.columns:\n",
    "            df.rename(columns={\"sentence\": \"Sentence\"}, inplace=True)\n",
    "        if \"sentence_num\" in df.columns:\n",
    "            df.rename(columns={\"sentence_num\": \"Sentence Num\"}, inplace=True)\n",
    "        if \"report_index\" in df.columns:\n",
    "            df.drop(columns=[\"report_index\"], inplace=True)\n",
    "        if \"Brain Related\" not in df.columns:\n",
    "            df[\"Brain Related\"] = -1\n",
    "        df[\"Brain Related\"] = df[\"Brain Related\"].fillna(-1).astype(int)\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "    \n",
    "    brain_text = get_report_text(df_brain)\n",
    "    face_text = get_report_text(df_face)\n",
    "    spine_text = get_report_text(df_spine)\n",
    "    \n",
    "    brain_sections = extract_sections(brain_text)\n",
    "    face_sections = extract_sections(face_text)\n",
    "    spine_sections = extract_sections(spine_text)\n",
    "    \n",
    "    SUFFIX = \"_deterministic\"\n",
    "    \n",
    "    variant = i % 4 # to preserve independence, we can only merge one way\n",
    "    if variant == 0:\n",
    "        merged = merge_sections_labeled([brain_sections], [1])\n",
    "        df_out = create_dataframe_from_merged(merged)\n",
    "        out_name = f\"synthetic_brain_{i:03d}{SUFFIX}.csv\"\n",
    "    \n",
    "    elif variant == 1:\n",
    "        merged = merge_sections_labeled([brain_sections, face_sections], [1, 0])\n",
    "        df_out = create_dataframe_from_merged(merged)\n",
    "        out_name = f\"synthetic_brain_face_{i:03d}{SUFFIX}.csv\"\n",
    "    \n",
    "    elif variant == 2:\n",
    "        merged = merge_sections_labeled([brain_sections, spine_sections], [1, 0])\n",
    "        df_out = create_dataframe_from_merged(merged)\n",
    "        out_name = f\"synthetic_brain_spine_{i:03d}{SUFFIX}.csv\"\n",
    "    \n",
    "    else:\n",
    "        merged = merge_sections_labeled([brain_sections, face_sections, spine_sections], [1, 0, 0])\n",
    "        df_out = create_dataframe_from_merged(merged)\n",
    "        out_name = f\"synthetic_brain_face_spine_{i:03d}{SUFFIX}.csv\"\n",
    "    \n",
    "    df_out.to_csv(os.path.join(OUTPUT_DIR, out_name), index=False)\n",
    "    print(f\"[variant {variant}] wrote {out_name} for brain report {i+1}/{len(brain_files)}\")\n",
    "    \n",
    "\n",
    "print(\"All authentic bundled reports generated in\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
